<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Specifications · IntervalMDP.jl</title><meta name="title" content="Specifications · IntervalMDP.jl"/><meta property="og:title" content="Specifications · IntervalMDP.jl"/><meta property="twitter:title" content="Specifications · IntervalMDP.jl"/><meta name="description" content="Documentation for IntervalMDP.jl."/><meta property="og:description" content="Documentation for IntervalMDP.jl."/><meta property="twitter:description" content="Documentation for IntervalMDP.jl."/><meta property="og:url" content="https://www.baymler.com/IntervalMDP.jl/specifications/"/><meta property="twitter:url" content="https://www.baymler.com/IntervalMDP.jl/specifications/"/><link rel="canonical" href="https://www.baymler.com/IntervalMDP.jl/specifications/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="IntervalMDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">IntervalMDP.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../usage/">Usage</a></li><li><a class="tocitem" href="../models/">Models</a></li><li class="is-active"><a class="tocitem" href>Specifications</a><ul class="internal"><li><a class="tocitem" href="#Simple-properties"><span>Simple properties</span></a></li><li><a class="tocitem" href="#Complex-properties"><span>Complex properties</span></a></li></ul></li><li><a class="tocitem" href="../algorithms/">Algorithms</a></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../reference/systems/">Systems</a></li><li><a class="tocitem" href="../reference/specifications/">Specifications</a></li><li><a class="tocitem" href="../reference/solve/">Solve Interface</a></li><li><a class="tocitem" href="../reference/data/">Data Storage</a></li><li><a class="tocitem" href="../api/">Index</a></li></ul></li><li><a class="tocitem" href="../data/">Data formats</a></li><li><a class="tocitem" href="../developer/">Developer docs</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Specifications</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Specifications</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Zinoex/IntervalMDP.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Zinoex/IntervalMDP.jl/blob/main/docs/src/specifications.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Specifications"><a class="docs-heading-anchor" href="#Specifications">Specifications</a><a id="Specifications-1"></a><a class="docs-heading-anchor-permalink" href="#Specifications" title="Permalink"></a></h1><p>Specifications are compromised of a property and whether to minimize or maximize either the lower bound (pessimistic) or the upper bound (optimistic) ofthe value function. The property, or goal, e.g. reachability and reach-avoid, defines both how the value function is initialized and how it is updated after every Bellman iteration. The property also defines whether the horizon is finite or infinite, which impacts the stopping criteria and the resulting strategy type. In particular, for the infinite horizon, model checking algorithm continues until a convergence threshold is met and the strategy, if performing control synthesis, is stationary, while for a finite horizon, the strategy is time varying. </p><div class="admonition is-info" id="Note-9751b515412af28e"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-9751b515412af28e" title="Permalink"></a></header><div class="admonition-body"><p>The adversary is never synthesized directly and is always considered time-varying and dynamic. Over the infinite horizon, similar to the strategy, a time-varying adversary at convergence coincides with a stationary and static adversary [<a href="../references/#suilen2024robust">5</a>]. Without loss of generality below, we assume that the adversary <span>$\eta$</span> and strategy <span>$\pi$</span> are given.</p></div></div><p>As an example of constructing the specification, we consider here a reachability specification for an IMDP.</p><pre><code class="language-julia hljs">time_horizon = 10
prop = FiniteTimeReachability([3, 9, 10], time_horizon)

spec = Specification(prop)  # Default: Pessimistic, Maximize

# Explicit satisfaction mode (pessimistic/optimistic)
spec = Specification(prop, Pessimistic) # Default: Maximize, useful for Markov chains
spec = Specification(prop, Optimistic)

# Explicit strategy mode (minimize/maxize)
spec = Specification(prop, Pessimistic, Maximize)
spec = Specification(prop, Pessimistic, Minimize)  # Unusual, but available
spec = Specification(prop, Optimistic, Maximize)  # Unusual, but available
spec = Specification(prop, Optimistic, Minimize)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">Specification</span>
├─ Satisfaction mode: <span class="sgr35">Optimistic</span>
├─ Strategy mode: <span class="sgr35">Minimize</span>
└─ Property: <span class="sgr36">FiniteTimeReachability</span>
   ├─ Time horizon: <span class="sgr35">10</span>
   └─ Reach states: <span class="sgr35">CartesianIndex{1}[CartesianIndex(3,), CartesianIndex(9,), CartesianIndex(10,)]</span>
</code></pre><h2 id="Simple-properties"><a class="docs-heading-anchor" href="#Simple-properties">Simple properties</a><a id="Simple-properties-1"></a><a class="docs-heading-anchor-permalink" href="#Simple-properties" title="Permalink"></a></h2><p>In the sections below, we will enumerate the possible simple properties (meaning no task automaton required), their equivalence to some value function, and how to construct them. For complex properties and how to construct task automata see <a href="#Complex-properties">Complex properties</a>,</p><h3 id="Reachability"><a class="docs-heading-anchor" href="#Reachability">Reachability</a><a id="Reachability-1"></a><a class="docs-heading-anchor-permalink" href="#Reachability" title="Permalink"></a></h3><p>Given a target set <span>$G \subset S$</span> and a horizon <span>$K \in \mathbb{N} \cup \{\infty\}$</span>, reachability is the following objective </p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{reach}}(G, K) = \mathbb{P}^{\pi, \eta} \left[\omega \in \Omega : \exists k \in \{0, \ldots, K\}, \, \omega[k] \in G \right].\]</p><p>The property is equivalent to the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= \mathbf{1}_{G}(s)\\
        V^{\pi, \eta}_k(s) &amp;= \mathbf{1}_{G}(s) + \mathbf{1}_{S \setminus G}(s) \mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{reach}}(G, K) = V_K(s)$</span>, where for <span>$K = \infty$</span> the adversary does not depend on time.</p><p>Example:</p><pre><code class="language-julia hljs"># Finite horizon
time_horizon = 10

# Example with a single state variable
prop = FiniteTimeReachability([3, 9, 10], time_horizon)          # Single state variable only
prop = FiniteTimeReachability([(3,), (9,), (10,)], time_horizon) # Format available for multiple state variables

# Example with 3 state variables
prop = FiniteTimeReachability([(4, 3, 9)], time_horizon)

# Infinite horizon
convergence_threshold = 1e-8
prop = InfiniteTimeReachability([3, 9, 10], convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">InfiniteTimeReachability</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
└─ Reach states: <span class="sgr35">CartesianIndex{1}[CartesianIndex(3,), CartesianIndex(9,), CartesianIndex(10,)]</span>
</code></pre><p>In addition to finite and infinite horizon reachability, we also define <em>exact</em> time reachability, which is the following property</p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{exact-reach}}(G, K) = \mathbb{P}^{\pi, \eta} \left[\omega \in \Omega : \omega[K] \in G \right],\]</p><p>which is equivalent with the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= \mathbf{1}_{G}(s)\\
        V^{\pi, \eta}_k(s) &amp;= \mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{exact-reach}}(G, K) = V_K(s)$</span> for a horizon <span>$K \in \mathbb{N}$</span>.</p><p>This can be constructed similarly</p><pre><code class="language-julia hljs">time_horizon = 10

# Example with a single state variable
prop = ExactTimeReachability([3, 9, 10], time_horizon)          # Single state variable only
prop = ExactTimeReachability([(3,), (9,), (10,)], time_horizon) # Format available for multiple state variables

# Example with 3 state variables
prop = ExactTimeReachability([(4, 3, 9)], time_horizon)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">ExactTimeReachability</span>
├─ Time horizon: <span class="sgr35">10</span>
└─ Reach states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(4, 3, 9)]</span>
</code></pre><h3 id="Reach-avoid"><a class="docs-heading-anchor" href="#Reach-avoid">Reach-avoid</a><a id="Reach-avoid-1"></a><a class="docs-heading-anchor-permalink" href="#Reach-avoid" title="Permalink"></a></h3><p>Given a target set <span>$G \subset S$</span>, an avoid set <span>$O \subset S$</span> (with <span>$G \cap O = \emptyset$</span>), and a horizon <span>$K \in \mathbb{N} \cup \{\infty\}$</span>, reach-avoid is the following objective </p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{reach-avoid}}(G, O, K) = \mathbb{P}^{\pi, \eta} \left[\omega \in \Omega : \exists k \in \{0, \ldots, K\}, \, \omega[k] \in G, \; \forall k&#39; \in \{0, \ldots, k&#39; \}, \, \omega[k] \notin O \right].\]</p><p>The property is equivalent to the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= \mathbf{1}_{G}(s)\\
        V^{\pi, \eta}_k(s) &amp;= \mathbf{1}_{G}(s) + \mathbf{1}_{S \setminus (G \cup O)}(s) \mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{reach-avoid}}(G, O, K) = V_K(s)$</span>, where for <span>$K = \infty$</span> the adversary does not depend on time.</p><p>Example:</p><pre><code class="language-julia hljs"># Finite horizon
time_horizon = 10

# Example with a single state variable
reach = [3, 9]
avoid = [10]
prop = FiniteTimeReachAvoid(reach, avoid, time_horizon) # Single state variable only

reach = [(3,), (9,)]
avoid = [(10,)]
prop = FiniteTimeReachAvoid(reach, avoid, time_horizon) # Format available for multiple state variables

# Example with 3 state variables
reach = [(4, 3, 9)]
avoid = [(1, 1, 9)]
prop = FiniteTimeReachAvoid(reach, avoid, time_horizon)

# Infinite horizon
convergence_threshold = 1e-8
prop = InfiniteTimeReachAvoid(reach, avoid, convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">InfiniteTimeReachAvoid</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
├─ Reach states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(4, 3, 9)]</span>
└─ Avoid states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(1, 1, 9)]</span>
</code></pre><p>We also define <em>exact</em> time reach-avoid, which is the following property</p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{exact-reach-avoid}}(G, O, K) = \mathbb{P}^{\pi, \eta} \left[\omega \in \Omega : \omega[K] \in G, \; \forall k \in \{0, \ldots, K\}, \, \omega[k] \notin O \right],\]</p><p>which is equivalent with the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= \mathbf{1}_{G}(s)\\
        V^{\pi, \eta}_k(s) &amp;= \mathbf{1}_{S \setminus O}(s)\mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{exact-reach}}(G, K) = V_K(s)$</span> for a horizon <span>$K \in \mathbb{N}$</span>.</p><p>This can be constructed similarly</p><pre><code class="language-julia hljs">time_horizon = 10

# Example with a single state variable
reach = [3, 9]
avoid = [10]
prop = ExactTimeReachAvoid(reach, avoid, time_horizon) # Single state variable only

reach = [(3,), (9,)]
avoid = [(10,)]
prop = ExactTimeReachAvoid(reach, avoid, time_horizon) # Format available for multiple state variables

# Example with 3 state variables
reach = [(4, 3, 9)]
avoid = [(1, 1, 9)]
prop = ExactTimeReachAvoid(reach, avoid, time_horizon)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">ExactTimeReachAvoid</span>
├─ Time horizon: <span class="sgr35">10</span>
├─ Reach states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(4, 3, 9)]</span>
└─ Avoid states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(1, 1, 9)]</span>
</code></pre><h3 id="Safety"><a class="docs-heading-anchor" href="#Safety">Safety</a><a id="Safety-1"></a><a class="docs-heading-anchor-permalink" href="#Safety" title="Permalink"></a></h3><p>Given an avoid set <span>$O \subset S$</span> and a horizon <span>$K \in \mathbb{N} \cup \{\infty\}$</span>, safety is the following objective </p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{safe}}(O, K) = \mathbb{P}^{\pi, \eta} \left[\omega \in \Omega : \forall k \in \{0, \ldots, K\}, \, \omega[k] \notin O \right].\]</p><p>This property can by duality with reachability equivalently be states as <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{safe}}(O, K) = 1 - \mathbb{P}^{\pi, \eta}_{\mathrm{reach}}(O, K)$</span>. Note that if the strategy and adversary are not given, their optimization direction must be flipped in the dual objective. Alternatively, the property can be stated via the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= -\mathbf{1}_{O}(s)\\
        V^{\pi, \eta}_k(s) &amp;= -\mathbf{1}_{O}(s) + \mathbf{1}_{S \setminus O}(s) \mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{safe}}(G, K) = 1 + V_K(s)$</span>, where for <span>$K = \infty$</span> the adversary does not depend on time. The benefit of this formulation is that the optimization directions need not be flipped.</p><p>Example:</p><pre><code class="language-julia hljs"># Finite horizon
time_horizon = 10

# Example with a single state variable
prop = FiniteTimeSafety([10], time_horizon)    # Single state variable only
prop = FiniteTimeSafety([(10,)], time_horizon) # Format available for multiple state variables

# Example with 3 state variables
prop = FiniteTimeSafety([(4, 3, 9)], time_horizon)

# Infinite horizon
convergence_threshold = 1e-8
prop = InfiniteTimeSafety([3, 9, 10], convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">InfiniteTimeSafety</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
└─ Avoid states: <span class="sgr35">CartesianIndex{1}[CartesianIndex(3,), CartesianIndex(9,), CartesianIndex(10,)]</span>
</code></pre><h3 id="Discounted-reward"><a class="docs-heading-anchor" href="#Discounted-reward">Discounted reward</a><a id="Discounted-reward-1"></a><a class="docs-heading-anchor-permalink" href="#Discounted-reward" title="Permalink"></a></h3><p>Given a (state) reward function <span>$r : S \to \mathbb{R}$</span>, a discount factor <span>$\nu \in (0, 1)$</span>, and a horizon <span>$K \in \mathbb{N} \cup \{\infty\}$</span>, a (discounted) reward objective is then follow</p><p class="math-container">\[\mathbb{E}^{\pi,\eta}_{\mathrm{reward}}(r, \nu, K) = \mathbb{E}^{\pi,\eta}\left[\sum_{k=0}^{K} \nu^k r(\omega[k]) \right].\]</p><p>For a finite horizon, the discount factor is allowed to be <span>$\nu = 1$</span>; for the infinite horizon, <span>$\nu &lt; 1$</span> is required for convergence.</p><p>The property is equivalent to the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= r(s)\\
        V^{\pi, \eta}_k(s) &amp;= r(s) + \nu \mathbb{E}_{t \sim \eta(s, a, K - k)}[V^{\pi, \eta}_{k - 1}(t)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{E}^{\pi,\eta}_{\mathrm{reward}}(r, \nu, K) = V_K(s)$</span>, where for <span>$K = \infty$</span> the adversary does not depend on time.</p><p>Example:</p><pre><code class="language-julia hljs"># Finite horizon
time_horizon = 10
discount_factor = 0.9

# Example with a single state variable
rewards = [0.0, 2.0, 1.0, -1.0]  # For 4 states
prop = FiniteTimeReward(rewards, discount_factor, time_horizon)

# Example with 2 state variables of 2 and 4 values respectively
rewards = [
    0.0  2.0  1.0 -1.0;
    1.0 -1.0  0.0  2.0
]
prop = FiniteTimeReward(rewards, discount_factor, time_horizon)

# Infinite horizon
convergence_threshold = 1e-8
prop = InfiniteTimeReward(rewards, discount_factor, convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">InfiniteTimeReward</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
├─ Discount factor: <span class="sgr35">0.9</span>
└─ Reward storage: <span class="sgr35">Float64, (2, 4)</span>
</code></pre><h3 id="Expected-exit-time"><a class="docs-heading-anchor" href="#Expected-exit-time">Expected exit time</a><a id="Expected-exit-time-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-exit-time" title="Permalink"></a></h3><p>Given a avoid set <span>$O \subset S$</span>, the expected exit time of the set <code>S \setminus O</code> is the following objective </p><p class="math-container">\[\mathbb{E}^{\pi,\eta}_{\mathrm{exit}}(O) = \mathbb{E}^{\pi,\eta}\left[k : \omega[k] \in O, \, \forall k&#39; \in \{0, \ldots, k - 1\}, \, \omega[k&#39;] \notin O \right].\]</p><p>The property is equivalent to the following value function</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s) &amp;= \mathbf{1}_{S \setminus 0}(s)\\
        V^{\pi, \eta}_k(s) &amp;= \mathbf{1}_{S \setminus O}(s) \left(1 + \mathbb{E}_{t \sim \eta(s, a)}[V^{\pi, \eta}_{k - 1}(t)]\right)
    \end{aligned}\]</p><p>such that <span>$\mathbb{E}^{\pi,\eta}_{\mathrm{exit}}(O) = V_\infty(s)$</span>. The adversary does not depend on time.</p><p>Example:</p><pre><code class="language-julia hljs">convergence_threshold = 1e-8

# Example with a single state variable
avoid_states = [10]
prop = ExpectedExitTime(avoid_states, convergence_threshold)    # Single state variable only

avoid_states = [(10,)]
prop = ExpectedExitTime(avoid_states, convergence_threshold) # Format available for multiple state variables

# Example with 3 state variables
avoid_states = [(4, 3, 9)]
prop = ExpectedExitTime(avoid_states, convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">ExpectedExitTime</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
└─ Avoid states: <span class="sgr35">CartesianIndex{3}[CartesianIndex(4, 3, 9)]</span>
</code></pre><h2 id="Complex-properties"><a class="docs-heading-anchor" href="#Complex-properties">Complex properties</a><a id="Complex-properties-1"></a><a class="docs-heading-anchor-permalink" href="#Complex-properties" title="Permalink"></a></h2><p>For complex, temporal properties, it is necessary to use some form of automaton to express the property. In this package, we support specifications via Deterministic Finite Automata (DFA), which via a lazy product construction with an fRMDP allows for efficient implementations of the Bellman operator. DFAs is an important class of task automata as it can express properties in syntactically co-safe Linear Temporal Logic (scLTL) [<a href="../references/#baier2008principles">10</a>] and Linear Temporal Logic over finite traces (LTLf) [<a href="../references/#de2013linear">11</a>].</p><p>Formally, a DFA is a tuple <span>$\mathcal{A} = (Q, q_0, 2^{\mathrm{AP}}, \delta, F)$</span> where <span>$Q$</span> is a finite set of states, <span>$q_0 \in Q$</span> is the initial state, <span>$2^{\mathrm{AP}}$</span> is a finite alphabet from atomic proposition <span>$\mathrm{AP}$</span>, <span>$\delta : Q \times 2^{\mathrm{AP}} \to Q$</span> is a transition function, and <span>$F \subseteq Q$</span> is a set of accepting states. The DFA accepts a word <span>$\sigma = \sigma_0 \sigma_1 \ldots \sigma_n$</span> over the alphabet <span>$2^{\mathrm{AP}}$</span> if there exists a sequence of states <span>$q_0, q_1, \ldots q_n$</span> such that <span>$q_{i+1} = \delta(q_i, \sigma_i)$</span> for all <span>$0 \geq i &lt; n$</span> and <span>$q_n \in F$</span>. We write <span>$\mathcal{A} \models \sigma$</span> if the word <span>$\sigma$</span> is accepted by the DFA <span>$\mathcal{A}$</span>.</p><p>A DFA can be constructed like in the following example<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>:</p><pre><code class="language-julia hljs">atomic_props = [&quot;a&quot;, &quot;b&quot;]

delta = TransitionFunction([  # Columns: states, rows: input symbols
    1 3 3  # symbol: &quot;&quot;
    2 1 3  # symbol: &quot;a&quot;
    3 3 3  # symbol: &quot;b&quot;
    1 1 1  # symbol: &quot;ab&quot;
])

initial_state = 1

dfa = DFA(delta, initial_state, atomic_props)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">DFA</span> (Deterministic Finite Automaton)
├─ Number of states: <span class="sgr35">3</span>
├─ Number of labels: <span class="sgr35">4</span>
└─ Initial state: <span class="sgr35">1</span>
</code></pre><p>Notice that the DFA does not include the set of accepting states. This is because the accepting states do not impact the Bellman operator and therefore are defined in <code>DFAReachability</code> objects, which is shown below.</p><pre><code class="language-julia hljs">accepting_states = [3]  # Accepting _DFA_ states

time_horizon = 10
prop = FiniteTimeDFAReachability(accepting_states, time_horizon)

convergence_threshold = 1e-8
prop = InfiniteTimeDFAReachability(accepting_states, convergence_threshold)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">InfiniteTimeDFAReachability</span>
├─ Convergence threshold: <span class="sgr35">1.0e-8</span>
└─ Reach states: <span class="sgr35">Int32[3]</span>
</code></pre><p>Given an fRMDP <span>$M = (S, S_0, A, \mathcal{G}, \Gamma)$</span> and a labeling function <span>$L : S \to \Sigma$</span> that maps states of the fRMDP to symbols in the alphabet of the DFA, a path <span>$\omega = s_0 s_1 \ldots$</span> in the fRMDP produces a word <span>$L(s_0) L(s_1) \ldots$</span> that is (possibly) accepted by the DFA. The probability of producing a path in the fRMDP that is accepted by the DFA can be expressed via the product construction <span>$M \otimes \mathcal{A} = (Z, Z_0, A, \Gamma&#39;)$</span>, where</p><ul><li><span>$Z = S \times Q$</span> is the set of product states, </li><li><span>$Z_0 = S_0 \times \{q_0\}$</span> is the set of initial product states,</li><li><span>$A$</span> is the set of actions, and</li><li><span>$\Gamma&#39; = \{\Gamma_{z, a}\}_{z \in Z, a \in A}$</span> is the joint ambiguity set defined as</li></ul><p class="math-container">\[\Gamma&#39;_{z, a} = \{\gamma&#39;_{z, a} \in \mathcal{D}(Z) : \exists \gamma_{s, a} \in \Gamma_{s, a} \text{ s.t. } \gamma&#39;_{z, a}(z&#39;) = \mathbf{1}_{q&#39;}(\delta(q, L(t))) \gamma_{s, a}(t)\}\]</p><p>where <span>$z = (s, q)$</span> and <span>$z&#39; = (t, q&#39;)$</span>. Then, the probability of generating a path, of length <span>$K \in \mathbb{N}$</span>, in the fRMDP that is accepted by the DFA is formally defined as</p><p class="math-container">\[\mathbb{P}^{\pi, \eta}_{\mathrm{dfa-reach}}(F, K) = \mathbb{P}^{\pi, \eta}_{M \otimes \mathcal{A}} \left[\omega \in \Omega : \omega[K] \in S \times F \right].\]</p><p>Note that this is equivalent to reachability in the product fRMDP <span>$M \otimes \mathcal{A}$</span>. Therefore, the property can equivalently be stated via the value function for reachability in the product fRMDP.</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(z) &amp;= \mathbf{1}_{S \times F}(z)\\
        V^{\pi, \eta}_k(z) &amp;= \mathbf{1}_{S \times F}(z) + \mathbf{1}_{Z \setminus (S \times F)}(z) \mathbb{E}_{z&#39; \sim \eta(z, a, K - k)}[V^{\pi, \eta}_{k - 1}(z&#39;)]
    \end{aligned}\]</p><p>such that <span>$\mathbb{P}^{\pi, \eta}_{\mathrm{dfa-reach}}(F, K) = V_K(z)$</span>. </p><p>Note that the product is never explicitly constructed, for three reasons: (i) the result is an RMDP and not an fRMDP, thus negating the computational benefits of using fRMDPs, (ii) the transition function will be sparse even if some marginals in the original fRMDP are dense, and (iii) the Bellman operator will not be able to leverage the structure of the product construction. Instead, we lazily construct the product as a <a href="../reference/systems/#IntervalMDP.ProductProcess"><code>ProductProcess</code></a>, and sequentially update the value function first updating wrt. the DFA transition and then wrt. the fRMDP transition like</p><p class="math-container">\[    \begin{aligned}
        V^{\pi, \eta}_0(s, q) &amp;= \mathbf{1}_{F}(q)\\
        W^{\pi, \eta}_k(t, q) &amp;= \mathbf{1}_{F}(q) + \mathbf{1}_{Q \setminus F}(q) V^{\pi, \eta}_{k - 1}(t, \delta(q, L(t)))\\
        V^{\pi, \eta}_k(s, q) &amp;= \mathbb{E}_{t \sim \eta(s, a, K - k)}[W^{\pi, \eta}_k(t, q)]
    \end{aligned}\]</p><p>Notice that <span>$W^{\pi, \eta}_k(t, q)$</span> is shared for all <span>$s \in S$</span> when updating <span>$V^{\pi, \eta}_k(s, q)$</span>. This allows for efficient, cache-friendly implementations of the Bellman operator. The kernel for product processes merely forwards, for each DFA state <span>$q \in Q \setminus F$</span>, the Bellman update to the underlying Bellman operator algorithm, which is chosen based on the fRMDP model type, e.g. IMDP or odIMDP, storage type, e.g. dense or sparse, and hardware, e.g. CPU or CUDA, for efficicency.</p><p>Example of constructing a product process:</p><pre><code class="language-julia hljs">map = [1, 2, 3]  # &quot;&quot;, &quot;a&quot;, &quot;b&quot;
lf = DeterministicLabelling(map)

product_process = ProductProcess(mdp, dfa, lf)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">ProductProcess</span>
├─ Underlying process:
│  <span class="sgr36">FactoredRobustMarkovDecisionProcess</span>
│  ├─ 1 state variables with cardinality: <span class="sgr35">(3,)</span>
│  ├─ 1 action variables with cardinality: <span class="sgr35">(2,)</span>
│  ├─ Initial states: <span class="sgr35">Int32[1]</span>
│  ├─ Transition marginals:
│  │  └─ Marginal 1: 
│  │     ├─ Conditional variables: <span class="sgr35">states = (1,), actions = (1,)</span>
│  │     └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
│  └─<span class="sgr31">Inferred properties</span>
│     ├─Model type: <span class="sgr32">Interval MDP</span>
│     ├─Number of states: <span class="sgr32">3</span>
│     ├─Number of actions: <span class="sgr32">2</span>
│     ├─Default model checking algorithm: <span class="sgr32">Robust Value Iteration</span>
│     └─Default Bellman operator algorithm: <span class="sgr32">O-Maximization</span>
├─ Automaton:
│  <span class="sgr36">DFA</span> (Deterministic Finite Automaton)
│  ├─ Number of states: <span class="sgr35">3</span>
│  ├─ Number of labels: <span class="sgr35">4</span>
│  └─ Initial state: <span class="sgr35">1</span>
└─ Labelling type: <span class="sgr35">DeterministicLabelling{Int64, Vector{Int64}}</span>
</code></pre><p>The product process can then be used in a <a href="../reference/specifications/#IntervalMDP.VerificationProblem"><code>VerificationProblem</code></a> or <a href="../reference/specifications/#IntervalMDP.ControlSynthesisProblem"><code>ControlSynthesisProblem</code></a> together with a specification with a DFA property.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>The automatic construction of a DFA from scLTL or LTLf formulae is not currently supported, but planned for future releases.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../models/">« Models</a><a class="docs-footer-nextpage" href="../algorithms/">Algorithms »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Tuesday 4 November 2025 09:15">Tuesday 4 November 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
