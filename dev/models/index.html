<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Models · IntervalMDP.jl</title><meta name="title" content="Models · IntervalMDP.jl"/><meta property="og:title" content="Models · IntervalMDP.jl"/><meta property="twitter:title" content="Models · IntervalMDP.jl"/><meta name="description" content="Documentation for IntervalMDP.jl."/><meta property="og:description" content="Documentation for IntervalMDP.jl."/><meta property="twitter:description" content="Documentation for IntervalMDP.jl."/><meta property="og:url" content="https://www.baymler.com/IntervalMDP.jl/models/"/><meta property="twitter:url" content="https://www.baymler.com/IntervalMDP.jl/models/"/><link rel="canonical" href="https://www.baymler.com/IntervalMDP.jl/models/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="IntervalMDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">IntervalMDP.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../usage/">Usage</a></li><li class="is-active"><a class="tocitem" href>Models</a><ul class="internal"><li><a class="tocitem" href="#Factored-RMDPs"><span>Factored RMDPs</span></a></li><li><a class="tocitem" href="#IMCs"><span>IMCs</span></a></li><li><a class="tocitem" href="#IMDPs"><span>IMDPs</span></a></li><li><a class="tocitem" href="#odIMDPs"><span>odIMDPs</span></a></li><li><a class="tocitem" href="#fIMDPs"><span>fIMDPs</span></a></li></ul></li><li><a class="tocitem" href="../specifications/">Specifications</a></li><li><a class="tocitem" href="../algorithms/">Algorithms</a></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../reference/systems/">Systems</a></li><li><a class="tocitem" href="../reference/specifications/">Specifications</a></li><li><a class="tocitem" href="../reference/solve/">Solve Interface</a></li><li><a class="tocitem" href="../reference/data/">Data Storage</a></li><li><a class="tocitem" href="../api/">Index</a></li></ul></li><li><a class="tocitem" href="../data/">Data formats</a></li><li><a class="tocitem" href="../developer/">Developer docs</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Zinoex/IntervalMDP.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Zinoex/IntervalMDP.jl/blob/main/docs/src/models.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Models"><a class="docs-heading-anchor" href="#Models">Models</a><a id="Models-1"></a><a class="docs-heading-anchor-permalink" href="#Models" title="Permalink"></a></h1><h4 id="Mathematical-Notation"><a class="docs-heading-anchor" href="#Mathematical-Notation">Mathematical Notation</a><a id="Mathematical-Notation-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Notation" title="Permalink"></a></h4><p>We denote the natural numbers by <span>$\mathbb{N}$</span> and <span>$\mathbb{N}_0 = \mathbb{N} \cup \{0\}$</span>. A probability distribution <span>$\gamma$</span> over a finite set <span>$S$</span> is a function <span>$\gamma : S \to [0, 1]$</span> satisfying <span>$\sum_{s \in S} \gamma(s) = 1$</span>. The support of the distribution <span>$\mathop{supp}(\gamma)$</span> is defined as <span>$\mathop{supp}(\gamma) = \{ s \in S : \gamma(s) &gt; 0\}$</span>. We denote by <span>$\mathcal{D}(S)$</span> the set of all probability distributions over <span>$S$</span>. For <span>$\underline{\gamma}, \overline{\gamma} : S \to [0, 1]$</span> such that <span>$\underline{\gamma}(s) \leq \overline{\gamma}(s)$</span> for each <span>$s \in S$</span> and <span>$\sum_{s \in S} \underline{\gamma}(s) \leq 1 \leq \sum_{s \in S} \overline{\gamma}(s)$</span>, an interval ambiguity set <span>$\Gamma \subset \mathcal{D}(S)$</span> is the set of distributions such that </p><p class="math-container">\[    \Gamma = \{ \gamma \in \mathcal{D}(S) \,:\, \underline{\gamma}(s) \leq \gamma(s) \leq \overline{\gamma}(s) \text{ for each } s \in S \}.\]</p><p><span>$\underline{\gamma}, \overline{\gamma}$</span> are referred to as the interval bounds of the interval ambiguity set. For <span>$n$</span> finite sets <span>$S_1, \ldots, S_n$</span> we denote by <span>$S_1 \times \cdots \times S_n$</span> their Cartesian product. Given <span>$S = S_1 \times \cdots \times S_n$</span> and <span>$n$</span> ambiguity sets <span>$\Gamma_i \in \mathcal{D}(S_i)$</span>, <span>$i = 1, \ldots, n$</span>, the product ambiguity set <span>$\Gamma \subseteq \mathcal{D}(S)$</span> is defined as: </p><p class="math-container">\[    \Gamma = \left\{ \gamma \in \mathcal{D}(S) \,:\, \gamma(s) = \prod_{i=1}^n \gamma^i(s^i), \, \gamma^i \in \Gamma_i \right\}\]</p><p>where <span>$s = (s_1, \ldots, s_n) \in S$</span>. We will denote the product ambiguity set as <span>$\Gamma = \bigotimes_{i=1}^n \Gamma_i$</span>. Each <span>$\Gamma_i$</span> is called a marginal or component ambiguity set. A transition is a triplet <span>$(s, a, t) \in S \times A \times S$</span> where <span>$s$</span> is the source state, <span>$a$</span> is the action, and <span>$t$</span> is the target state.</p><h2 id="Factored-RMDPs"><a class="docs-heading-anchor" href="#Factored-RMDPs">Factored RMDPs</a><a id="Factored-RMDPs-1"></a><a class="docs-heading-anchor-permalink" href="#Factored-RMDPs" title="Permalink"></a></h2><p>Factored Robust Markov Decision Processes (fRMDPs) [<a href="../references/#schnitzer2025efficient">1</a>, <a href="../references/#delgado2011efficient">2</a>] are an extension of Robust Markov Decision Processes (RMDPs) [<a href="../references/#nilim2005robust">3</a>–<a href="../references/#suilen2024robust">5</a>] that incorporate a factored representation of the state and action spaces, i.e. with state and action variables. This allows for a more compact representation of the transition model and flexibility in modeling complex systems. First, we define here fRMDPs, and then in the subsequent sections, we define various special subclasses of fRMDPs, including how they relate to each other and to fRMDPs.</p><p>Formally, a fRMDP <span>$M$</span> is a tuple <span>$M = (S, S_0, A, \mathcal{G}, \Gamma)$</span>, where</p><ul><li><span>$S = S_1 \times \cdots \times S_n$</span> is a finite set of joint states with <span>$S_i$</span> being a finite set of states for the <span>$i$</span>-th state variable,</li><li><span>$S_0 \subseteq S$</span> is a set of initial states,</li><li><span>$A = A_1 \times \cdots \times A_m$</span> is a finite set of joint actions with <span>$A_j$</span> being a finite set of actions for the <span>$j$</span>-th action variable,</li><li><span>$\mathcal{G} = (\mathcal{V}, \mathcal{E})$</span> is a directed bipartite graph with nodes <span>$\mathcal{V} = \mathcal{V}_{ind} \cup \mathcal{V}_{cond} = \{S_1, \ldots, S_n, A_1, \ldots, A_m\} \cup \{S&#39;_1, \ldots, S&#39;_n\}$</span> representing the state and action variables and their next-state counterparts, and edges <span>$\mathcal{E} \subseteq \mathcal{V}_{ind} \times \mathcal{V}_{cond}$</span> representing dependencies of <span>$S&#39;_i$</span> on <span>$S_j$</span> and <span>$A_k$</span>,</li><li><span>$\Gamma = \{\Gamma_{s, a}\}_{s \in S, a \in A}$</span> is a set of ambiguity sets for source-action pair <span>$(s, a)$</span>, where each <span>$\Gamma_{s, a} = \bigotimes_{i=1}^n \Gamma^i_{\text{Pa}_\mathcal{G}(S&#39;_i) \cap (s, a)}$</span> is a product of ambiguity sets <span>$\Gamma^i_{\text{Pa}_\mathcal{G}(S&#39;_i) \cap (s, a)}$</span> along each marginal <span>$i$</span> conditional on the values in <span>$(s, a)$</span> of the parent variables <span>$\text{Pa}_\mathcal{G}(S&#39;_i)$</span> of <span>$S&#39;_i$</span> in <span>$\mathcal{G}$</span>, i.e.</li></ul><p class="math-container">\[    \Gamma_{s, a} = \left\{ \gamma \in \mathcal{D}(S) \,:\, \gamma(t) = \prod_{i=1}^n \gamma^i(t_i | s_{\text{Pa}_{\mathcal{G}_S}(S&#39;_i)}, a_{\text{Pa}_{\mathcal{G}_A}(S&#39;_i)}), \, \gamma^i(\cdot | s_{\text{Pa}_{\mathcal{G}_S}(S&#39;_i)}, a_{\text{Pa}_{\mathcal{G}_A}(S&#39;_i)}) \in \Gamma^i_{\text{Pa}_\mathcal{G}(S&#39;_i)} \right\}.\]</p><p>For a given source-action pair <span>$(s, a) \in S \times A$</span>, any distribution <span>$\gamma_{s, a} \in \Gamma_{s, a}$</span> is called a feasible distribution, and feasible transitions are triplets <span>$(s, a, t) \in S \times A \times S$</span> where <span>$t \in \mathop{supp}(\gamma_{s, a})$</span> for any feasible distribution <span>$\gamma_{s, a} \in \Gamma_{s, a}$</span>. A path of an fRMDP is a sequence of states and actions <span>$\omega = s[0], a[0], s[1], a[1], \dots$</span> where <span>$s[k] \in S$</span> and <span>$a[k] \in A$</span> for all <span>$k \in \mathbb{N}_0$</span>, and <span>$(s[k], a[k], s[k + 1])$</span> is a feasible transition  for all <span>$k \in \mathbb{N}_0$</span>. We denote by <span>$\omega[k] = s[k]$</span> the state of the path at time <span>$k \in \mathbb{N}_0$</span> and by <span>$\Omega$</span> and <span>$\Omega_{fin}$</span> the set of all infinite and finite paths, respectively.</p><p>A <em>strategy</em> or <em>policy</em> for an fRMDP is a function <span>$\pi : \Omega_{fin} \to A$</span> that assigns an action, given a (finite) path called the history. <em>Time-dependent</em> Markov strategies are functions from state and time step to an action, i.e. <span>$\pi : S \times \mathbb{N}_0 \to A$</span>. This can equivalently be described as a sequence of functions indexed by time <span>$\mathbf{\pi} = (\pi[0], \pi[1], \ldots)$</span>. If <span>$\pi$</span> does not depend on time and solely depends on the current state, it is called a <em>stationary</em> strategy. Similar to a strategy, an adversary <span>$\eta$</span> is a function that assigns a feasible distribution to a given state. The focus of this package is on dynamic uncertainties where the choice of the adversary is resolved at every time step, called dynamic uncertainty, and where the adversary has access to both the current state and action, called <span>$(s, a)$</span>-rectangularity. We refer to [<a href="../references/#suilen2024robust">5</a>] for further details on the distinction between static and dynamic uncertainties, types of rectangularity, and their implications. Given a strategy and an adversary, an fRMDP collapses to a finite (factored) Markov chain.</p><p>Below is an example of how to construct an fRMDP with 2 state variables (2 and 3 values respectively) and 2 action variables (1 and 2 values respectively), where each marginal ambiguity set is an interval ambiguity set. The first marginal depends on both state variables and the first action variable, while the second marginal only depends on the second state variable and the second action variable.</p><pre><code class="language-julia hljs">state_vars = (2, 3)
action_vars = (1, 2)

state_indices = (1, 2)
action_indices = (1,)
state_dims = (2, 3)
action_dims = (1,)
marginal1 = Marginal(IntervalAmbiguitySets(;
    # 6 ambiguity sets = 2 * 3 source states, 1 action
    # Column layout: (a¹₁, s¹₁, s²₁), (a¹₁, s¹₂, s²₁), (a¹₁, s¹₁, s²₂), (a¹₁, s¹₂, s²₂), (a¹₁, s¹₁, s²₃), (a¹₁, s¹₂, s²₃)
    # Equivalent to CartesianIndices(actions_dims..., state_dims...), i.e. actions first, then states in lexicographic order
    lower = [
        1/15  7/30  1/15  13/30  4/15  1/6
        2/5   7/30  1/30  11/30  2/15  1/10
    ],
    upper = [
        17/30  7/10   2/3   4/5  7/10  2/3
        9/10   13/15  9/10  5/6  4/5   14/15
    ]
), state_indices, action_indices, state_dims, action_dims)

state_indices = (2,)
action_indices = (2,)
state_dims = (3,)
action_dims = (2,)
marginal2 = Marginal(IntervalAmbiguitySets(;
    # 6 ambiguity sets = 3 source states, 2 actions
    # Column layout: (a²₁, s²₁), (a²₂, s²₁), (a²₁, s²₂), (a²₂, s²₂), (a²₁, s²₃), (a²₂, s²₃)
    # Equivalent to CartesianIndices(actions_dims..., state_dims...), i.e. actions first, then states in lexicographic order
    lower = [
        1/30  1/3   1/6   1/15  2/5   2/15
        4/15  1/4   1/6   1/30  2/15  1/30
        2/15  7/30  1/10  7/30  7/15  1/5
    ],
    upper = [
        2/3    7/15  4/5    11/30  19/30  1/2
        23/30  4/5   23/30  3/5    7/10   8/15
        7/15   4/5   23/30  7/10   7/15   23/30
    ]
), state_indices, action_indices, state_dims, action_dims)

initial_states = [(1, 1)]  # Initial states are optional
mdp = FactoredRobustMarkovDecisionProcess(state_vars, action_vars, (marginal1, marginal2), initial_states)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">FactoredRobustMarkovDecisionProcess</span>
├─ 2 state variables with cardinality: <span class="sgr35">(2, 3)</span>
├─ 2 action variables with cardinality: <span class="sgr35">(1, 2)</span>
├─ Initial states: <span class="sgr35">[(1, 1)]</span>
├─ Transition marginals:
│  ├─ Marginal 1: 
│  │  ├─ Conditional variables: <span class="sgr35">states = (1, 2), actions = (1,)</span>
│  │  └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
│  └─ Marginal 2: 
│     ├─ Conditional variables: <span class="sgr35">states = (2,), actions = (2,)</span>
│     └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
└─<span class="sgr31">Inferred properties</span>
   ├─Model type: <span class="sgr32">Factored Interval MDP</span>
   ├─Number of states: <span class="sgr32">6</span>
   ├─Number of actions: <span class="sgr32">2</span>
   ├─Default model checking algorithm: <span class="sgr32">Robust Value Iteration</span>
   └─Default Bellman operator algorithm: <span class="sgr32">Recursive O-Maximization</span>
</code></pre><div class="admonition is-category-warn" id="Warn-695be03ebc54b763"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-695be03ebc54b763" title="Permalink"></a></header><div class="admonition-body"><p>Notice that source-action pairs are on the columns of the matrices to defined the interval bounds. This is counter to most literature on transition matrices where transitions are from row to column. The choice of layout is to ensure that the memory access pattern is cache-friendly, as each column is stored contiguously in memory (column-major) and the Bellman updates iterate outer-most over source-action pairs. However, it also has a fundamental mathematical justification: the transition matrix can be viewed as a linear operator and the matrix form of a linear operator is defined such that the columns correspond to the input dimensions, i.e. from column to row. Furthermore, actions for the same source state are stored contiguously, which is also important for cache efficiency.</p></div></div><p>A general and useful subclass of fRMDPs is when each marginal ambiguity set is an interval ambiguity set. This subclass is called factored IMDPs (fIMDPs) and is described in more detail <a href="#fIMDPs">below</a>.</p><h2 id="IMCs"><a class="docs-heading-anchor" href="#IMCs">IMCs</a><a id="IMCs-1"></a><a class="docs-heading-anchor-permalink" href="#IMCs" title="Permalink"></a></h2><p>Interval Markov Chains (IMCs) [<a href="../references/#delahaye2011decision">6</a>] are a subclass of fRMDPs and a generalization of Markov Chains (MCs), where the transition probabilities are not known exactly, but they are constrained to be in some probability interval. Formally, an IMC <span>$M$</span> is a tuple <span>$M = (S, S_0, \Gamma)$</span>, where</p><ul><li><span>$S$</span> is a finite set of states,</li><li><span>$S_0 \subseteq S$</span> is a set of initial states,</li><li><span>$\Gamma = \{\Gamma_{s}\}_{s \in S}$</span> is a set of ambiguity sets for source state <span>$s$</span>, where each <span>$\Gamma_{s}$</span> is an interval ambiguity set over <span>$S$</span>.</li></ul><p>An IMC is equivalent to an fRMDP where there is only one state variable, no action variables, and the ambiguity sets are interval ambiguity sets. The dependency graph is just two nodes <span>$S$</span> and <span>$S&#39;$</span> with a single edge from the former to the latter. Paths and adversaries are defined similarly to fRMDPs.</p><p>Example:</p><pre><code class="language-julia hljs">prob = IntervalAmbiguitySets(;
    lower = [
        0     1/2   0
        1/10  3/10  0
        1/5   1/10  1
    ],
    upper = [
        1/2   7/10  0
        3/5   1/2   0
        7/10  3/10  1
    ],
)

initial_states = [1]  # Initial states are optional
mc = IntervalMarkovChain(prob, initial_states)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">FactoredRobustMarkovDecisionProcess</span>
├─ 1 state variables with cardinality: <span class="sgr35">(3,)</span>
├─ 1 action variables with cardinality: <span class="sgr35">(1,)</span>
├─ Initial states: <span class="sgr35">[1]</span>
├─ Transition marginals:
│  └─ Marginal 1: 
│     ├─ Conditional variables: <span class="sgr35">states = (1,), actions = (1,)</span>
│     └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
└─<span class="sgr31">Inferred properties</span>
   ├─Model type: <span class="sgr32">Interval MDP</span>
   ├─Number of states: <span class="sgr32">3</span>
   ├─Number of actions: <span class="sgr32">1</span>
   ├─Default model checking algorithm: <span class="sgr32">Robust Value Iteration</span>
   └─Default Bellman operator algorithm: <span class="sgr32">O-Maximization</span>
</code></pre><h2 id="IMDPs"><a class="docs-heading-anchor" href="#IMDPs">IMDPs</a><a id="IMDPs-1"></a><a class="docs-heading-anchor-permalink" href="#IMDPs" title="Permalink"></a></h2><p>Interval Markov Decision Processes (IMDPs) [<a href="../references/#givan2000bounded">7</a>, <a href="../references/#lahijanian2015formal">8</a>], also called bounded-parameter MDPs, are a subclass of fRMDPs and a generalization of MDPs, where the transition probabilities, given source state and action, are not known exactly, but they are constrained to be in some probability interval. IMDPs generalized IMCs by adding actions. Formally, an IMDP <span>$M$</span> is a tuple <span>$M = (S, S_0, A, \Gamma)$</span>, where</p><ul><li><span>$S$</span> is a finite set of states,</li><li><span>$S_0 \subseteq S$</span> is a set of initial states,</li><li><span>$A$</span> is a finite set of actions,</li><li>`<span>$\Gamma = \{\Gamma_{s, a}\}_{s \in S, a \in A}$</span> is a set of ambiguity sets for source-action pair <span>$(s, a)$</span>, where each <span>$\Gamma_{s, a}$</span> is an interval ambiguity set over <span>$S$</span>.</li></ul><p>An IMDP is equivalent to an fRMDP where there is only one state variable, one action variable, and the ambiguity sets are interval ambiguity sets. The dependency graph is three nodes <span>$S$</span>, <span>$A$</span>, and <span>$S&#39;$</span> with two edges <span>$S \rightarrow S&#39;$</span> and <span>$A \rightarrow S&#39;$</span>. Paths and adversaries are defined similarly to fRMDPs.</p><p>Example:</p><pre><code class="language-julia hljs">prob1 = IntervalAmbiguitySets(;
    lower = [
        0    1/2
        1/10 3/10
        1/5  1/10
    ],
    upper = [
        1/2  7/10
        3/5  1/2
        7/10 3/10
    ],
)

prob2 = IntervalAmbiguitySets(;
    lower = [
        1/10 1/5
        1/5  3/10
        3/10 2/5
    ],
    upper = [
        3/5 3/5
        1/2 1/2
        2/5 2/5
    ],
)

prob3 = IntervalAmbiguitySets(;
    lower = Float64[
        0 0
        0 0
        1 1
    ],
    upper = Float64[
        0 0
        0 0
        1 1
    ]
)

initial_states = [1]
mdp = IntervalMarkovDecisionProcess([prob1, prob2, prob3], initial_states)

# alternatively
prob = IntervalAmbiguitySets(;
    lower = [
        0    1/2  1/10 1/5  0 0
        1/10 3/10 1/5  3/10 0 0
        1/5  1/10 3/10 2/5  1 1
    ],
    upper = [
        1/2  7/10 3/5 2/5 0 0
        3/5  1/2  1/2 2/5 0 0
        7/10 3/10 2/5 2/5 1 1
    ],
)

num_actions = 2
mdp = IntervalMarkovDecisionProcess(prob, num_actions, initial_states)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">FactoredRobustMarkovDecisionProcess</span>
├─ 1 state variables with cardinality: <span class="sgr35">(3,)</span>
├─ 1 action variables with cardinality: <span class="sgr35">(2,)</span>
├─ Initial states: <span class="sgr35">[1]</span>
├─ Transition marginals:
│  └─ Marginal 1: 
│     ├─ Conditional variables: <span class="sgr35">states = (1,), actions = (1,)</span>
│     └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
└─<span class="sgr31">Inferred properties</span>
   ├─Model type: <span class="sgr32">Interval MDP</span>
   ├─Number of states: <span class="sgr32">3</span>
   ├─Number of actions: <span class="sgr32">2</span>
   ├─Default model checking algorithm: <span class="sgr32">Robust Value Iteration</span>
   └─Default Bellman operator algorithm: <span class="sgr32">O-Maximization</span>
</code></pre><p>It is possible to skip defining actions when the transition is a guaranteed self-loop and is the last states in the ambiguity set.  This is useful for defining target states in reachability problems. The example below has 3 states (as shown by the 3 rows) and 2 actions (explictly defined by <code>num_actions = 2</code>). The last state is a target state with a guaranteed self-loop, i.e., the transition probabilities are <span>$P(3 | 3, a) = 1$</span> for both actions <span>$a \in \{1, 2\}$</span>.</p><pre><code class="language-julia hljs">prob = IntervalAmbiguitySets(;
    lower = [
        0    1/2  1/10 1/5
        1/10 3/10 1/5  3/10
        1/5  1/10 3/10 2/5
    ],
    upper = [
        1/2  7/10 3/5 2/5
        3/5  1/2  1/2 2/5
        7/10 3/10 2/5 2/5
    ],
)

num_actions = 2
mdp = IntervalMarkovDecisionProcess(prob, num_actions)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36">FactoredRobustMarkovDecisionProcess</span>
├─ 1 state variables with cardinality: <span class="sgr35">(3,)</span>
├─ 1 action variables with cardinality: <span class="sgr35">(2,)</span>
├─ Initial states: <span class="sgr35">All states</span>
├─ Transition marginals:
│  └─ Marginal 1: 
│     ├─ Conditional variables: <span class="sgr35">states = (1,), actions = (1,)</span>
│     └─ Ambiguity set type: Interval (dense, <span class="sgr36">Matrix{Float64}</span>)
└─<span class="sgr31">Inferred properties</span>
   ├─Model type: <span class="sgr32">Interval MDP</span>
   ├─Number of states: <span class="sgr32">3</span>
   ├─Number of actions: <span class="sgr32">2</span>
   ├─Default model checking algorithm: <span class="sgr32">Robust Value Iteration</span>
   └─Default Bellman operator algorithm: <span class="sgr32">O-Maximization</span>
</code></pre><h2 id="odIMDPs"><a class="docs-heading-anchor" href="#odIMDPs">odIMDPs</a><a id="odIMDPs-1"></a><a class="docs-heading-anchor-permalink" href="#odIMDPs" title="Permalink"></a></h2><p>Orthogonally-decoupled IMDPs (odIMDPs) [<a href="../references/#mathiesen2025scalable">9</a>] are a subclass of fRMDPs designed to be more memory-efficient than IMDPs. The states are structured into an orthogonal, or grid-based, decomposition and the transition probability ambiguity sets, for each source-action pair, as a product of interval ambiguity sets along each marginal. </p><p>Formally, an odIMDP <span>$M$</span> with <span>$n$</span> marginals is a tuple <span>$M = (S, S_0, A, \Gamma)$</span>, where</p><ul><li><span>$S = S_1 \times \cdots \times S_n$</span> is a finite set of joint states with <span>$S_i$</span> being a finite set of states for the <span>$i$</span>-th marginal,</li><li><span>$S_0 \subseteq S$</span> is a set of initial states,</li><li><span>$A$</span> is a finite set of actions,</li><li><span>$\Gamma = \{\Gamma_{s, a}\}_{s \in S, a \in A}$</span> is a set of ambiguity sets for source-action pair <span>$(s, a)$</span>, where each <span>$\Gamma_{s, a} = \bigotimes_{i=1}^n \Gamma^i_{s, a}$</span> with <span>$\Gamma^i_{s, a}$</span> is an interval ambiguity set over the <span>$i$</span>-th marginal, i.e. over <span>$S_i$</span>.</li></ul><p>An odIMDP is equivalent to an fRMDP where the dependency graph is <span>$\mathcal{G} = (\mathcal{V}, \mathcal{E})$</span> with <span>$\mathcal{V} = \{S_1, \ldots, S_n, A\} \cup \{S&#39;_1, \ldots, S&#39;_n\}$</span> and <span>$\mathcal{E} = \{(S_i, S&#39;_j) : i, j = 1, \ldots, n\} \cup \{(A_i, S&#39;_j) : j = 1, \ldots, m, i = 1, \ldots, n\}$</span>. In other words, each next-state variable <span>$S&#39;_i$</span> depends on all state and action variables and the dependency graph is a complete bipartite graph. Paths, strategies, and adversaries are defined similarly to fRMDPs.</p><h2 id="fIMDPs"><a class="docs-heading-anchor" href="#fIMDPs">fIMDPs</a><a id="fIMDPs-1"></a><a class="docs-heading-anchor-permalink" href="#fIMDPs" title="Permalink"></a></h2><p>Factored IMDPs (fIMDPs) are a subclass of fRMDPs where each marginal ambiguity set is an interval ambiguity set, but where the dependency graph can be arbitrary.  Formally, an fIMDP <span>$M$</span> with <span>$n$</span> marginals is a tuple <span>$M = (S, S_0, A, \mathcal{G}, \Gamma)$</span>, where</p><ul><li><span>$S = S_1 \times \cdots \times S_n$</span> is a finite set of joint states with <span>$S_i$</span> being a finite set of states for the <span>$i$</span>-th marginal,</li><li><span>$S_0 \subseteq S$</span> is a set of initial states,</li><li><span>$A$</span> is a finite set of actions,</li><li><span>$\mathcal{G} = (\mathcal{V}, \mathcal{E})$</span> is a directed bipartite graph with nodes <span>$\mathcal{V} = \mathcal{V}_{ind} \cup \mathcal{V}_{cond} = \{S_1, \ldots, S_n, A_1, \ldots, A_m\} \cup \{S&#39;_1, \ldots, S&#39;_n\}$</span> representing the state and action variables and their next-state counterparts, and edges <span>$\mathcal{E} \subseteq \mathcal{V}_{ind} \times \mathcal{V}_{cond}$</span> representing dependencies of <span>$S&#39;_i$</span> on <span>$S_j$</span> and <span>$A_k$</span>,</li><li><span>$\Gamma = \{\Gamma_{s, a}\}_{s \in S, a \in A}$</span> is a set of ambiguity sets for source-action pair <span>$(s, a)$</span>, where each <span>$\Gamma_{s, a} = \bigotimes_{i=1}^n \Gamma^i_{\text{Pa}_\mathcal{G}(S&#39;_i) \cap (s, a)}$</span> with <span>$\Gamma^i_{\text{Pa}_\mathcal{G}(S&#39;_i) \cap (s, a)}$</span> is an interval ambiguity set over the <span>$i$</span>-th marginal, i.e. over <span>$S_i$</span>, conditional on the values in <span>$(s, a)$</span> of the parent variables <span>$\text{Pa}_\mathcal{G}(S&#39;_i)$</span> of <span>$S&#39;_i$</span> in <span>$\mathcal{G}$</span>.</li></ul><p>The example in <a href="#Factored-RMDPs">Factored RMDPs</a> is also an example of an fIMDP.</p><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><div class="citation noncanonical"><dl><dt>[1]</dt><dd><div>Y. Schnitzer, A. Abate and D. Parker. <em>Efficient Solution and Learning of Robust Factored MDPs</em>, arXiv preprint arXiv:2508.00707 (2025), <a href="https://arxiv.org/abs/2508.00707">arXiv:2508.00707</a>.</div></dd><dt>[2]</dt><dd><div>K. V. Delgado, S. Sanner and L. N. De Barros. <em>Efficient solutions to factored MDPs with imprecise transition probabilities</em>. Artificial Intelligence <strong>175</strong>, 1498–1527 (2011).</div></dd><dt>[3]</dt><dd><div>A. Nilim and L. El Ghaoui. <em>Robust control of Markov decision processes with uncertain transition matrices</em>. Operations Research <strong>53</strong>, 780–798 (2005).</div></dd><dt>[4]</dt><dd><div>W. Wiesemann, D. Kuhn and B. Rustem. <em>Robust Markov decision processes</em>. Mathematics of Operations Research <strong>38</strong>, 153–183 (2013).</div></dd><dt>[5]</dt><dd><div>M. Suilen, T. Badings, E. M. Bovy, D. Parker and N. Jansen. <em>Robust markov decision processes: A place where AI and formal methods meet</em>. In: <em>Principles of Verification: Cycling the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the Occasion of His 60th Birthday, Part III</em> (Springer, 2024); pp. 126–154, <a href="https://arxiv.org/abs/2411.11451">arXiv:2411.11451</a>.</div></dd><dt>[6]</dt><dd><div>B. Delahaye, K. G. Larsen, A. Legay, M. L. Pedersen and A. Wąsowski. <em>Decision problems for interval Markov chains</em>. In: <em>International Conference on Language and Automata Theory and Applications</em> (Springer, 2011); pp. 274–285.</div></dd><dt>[7]</dt><dd><div>R. Givan, S. Leach and T. Dean. <em>Bounded-parameter Markov decision processes</em>. Artificial Intelligence <strong>122</strong>, 71–109 (2000).</div></dd><dt>[8]</dt><dd><div>M. Lahijanian, S. B. Andersson and C. Belta. <em>Formal verification and synthesis for discrete-time stochastic systems</em>. IEEE Transactions on Automatic Control <strong>60</strong>, 2031–2045 (2015).</div></dd><dt>[9]</dt><dd><div>F. B. Mathiesen, S. Haesaert and L. Laurenti. <em>Scalable control synthesis for stochastic systems via structural IMDP abstractions</em>. In: <em>Proceedings of the 28th ACM International Conference on Hybrid Systems: Computation and Control</em> (2025); pp. 1–12, <a href="https://arxiv.org/abs/2411.11803">arXiv:2411.11803</a>.</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../usage/">« Usage</a><a class="docs-footer-nextpage" href="../specifications/">Specifications »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 5 December 2025 09:32">Friday 5 December 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
